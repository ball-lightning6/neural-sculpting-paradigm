import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
from tqdm import tqdm
import pandas as pd
from transformers import AutoImageProcessor, AutoModelForImageClassification
from sklearn.metrics import accuracy_score
import json

# ==============================================================================
# --- 1. é…ç½®åŒºåŸŸ (å·²æ•´åˆå’Œæ›´æ–°) ---
# ==============================================================================

# --- æ¨¡å‹é…ç½® ---
# MODEL_NAME = "microsoft/swin-base-patch4-window7-224-in22k"
MODEL_NAME = r"swin"
NUM_LABELS = 36

# --- æ•°æ®é›†é…ç½® ---
# IMAGE_DIR = "autodl-tmp/cnn_rainwater_dataset_mp/initial_images"
# METADATA_PATH = "autodl-tmp/cnn_rainwater_dataset_mp/metadata.csv"
IMAGE_DIR = "autodl-tmp/line_angle/images"
LABEL_DIR = "autodl-tmp/line_angle"

# --- è®­ç»ƒå‚æ•° ---
OUTPUT_DIR = "./checkpoints_swin_classifier_full"
LOG_FILE = os.path.join(OUTPUT_DIR, "training_log_full.txt")
BATCH_SIZE = 32
LEARNING_RATE = 5e-5  # Full fine-tuning might benefit from a slightly smaller LR
NUM_EPOCHS = 50  # Adjust as needed
FP16 = torch.cuda.is_available()
EVAL_EVERY_N_STEPS = 1000  # æ¯Næ­¥è¯„ä¼°ä¸€æ¬¡


# ==============================================================================
# --- 2. è‡ªå®šä¹‰å›¾åƒæ•°æ®é›† (ä¿æŒä¸å˜) ---
# ==============================================================================

class CountingDataset(Dataset):
    """
    ä¸€ä¸ªä¸“é—¨ç”¨äºè¯»å–å½¢çŠ¶è®¡æ•°å›¾åƒå’Œ12-bitæ ‡ç­¾çš„Datasetç±»ã€‚
    """

    def __init__(self, image_dir, label_dir, image_processor):
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.image_processor = image_processor
        self.image_files = sorted([os.path.splitext(f)[0] for f in os.listdir(image_dir) if f.endswith('.png')])
        self.label_file_path = os.path.join(self.label_dir, 'labels.json')
        with open(self.label_file_path, 'r') as f:
            self.labels = json.loads(f.read())

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        base_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, f"{base_name}.png")
        image = Image.open(img_path).convert("RGB")
        label = self.labels[f"{base_name}.png"]

        # ImageProcessor ä¼šè‡ªåŠ¨å¤„ç†Swin Transformeréœ€è¦çš„è¾“å…¥æ ¼å¼
        pixel_values = self.image_processor(image, return_tensors="pt")['pixel_values'].squeeze(0)

        label_tensor = torch.tensor(label, dtype=torch.float)

        return {
            "pixel_values": pixel_values,
            "labels": label_tensor
        }


class RainwaterImageDataset(Dataset):
    """
    ä¸€ä¸ªPyTorch Datasetç±»ã€‚
    ç”¨äºä»ä¸€ä¸ªå…ƒæ•°æ®CSVæ–‡ä»¶å’Œå¯¹åº”çš„å›¾åƒæ–‡ä»¶å¤¹ä¸­ä¸ºâ€œæ¥é›¨æ°´â€é—®é¢˜åŠ è½½æ ·æœ¬ã€‚
    """

    def __init__(self, metadata_path, images_dir, image_processor):
        self.images_dir = images_dir
        self.image_processor = image_processor
        self.metadata_df = pd.read_csv(metadata_path)

    def __len__(self):
        return len(self.metadata_df)

    def __getitem__(self, idx):
        row = self.metadata_df.iloc[idx]
        image_filename = row['initial_image']
        img_path = os.path.join(self.images_dir, image_filename)
        image = Image.open(img_path).convert("RGB")

        label_str = str(row['final_label'])
        label_list = [int(bit) for bit in label_str]
        label_tensor = torch.tensor(label_list, dtype=torch.float32)

        # Swin Transformerçš„å¤„ç†å™¨ä¼šå¤„ç†å½’ä¸€åŒ–ã€å°ºå¯¸è°ƒæ•´å’Œåˆ°å¼ é‡çš„è½¬æ¢
        pixel_values = self.image_processor(images=image, return_tensors="pt")['pixel_values'].squeeze(0)

        # è¿”å›çš„å­—å…¸é”®åä¸è®­ç»ƒå¾ªç¯ä¸­çš„ä½¿ç”¨ä¿æŒä¸€è‡´
        return {"pixel_values": pixel_values, "labels": label_tensor}


# ==============================================================================
# --- 3. è¯„ä¼°å‡½æ•° (æ‰‹åŠ¨) ---
# ==============================================================================

def evaluate(model, dataloader, criterion, device):
    """æ‰‹åŠ¨æ‰§è¡Œè¯„ä¼°"""
    model.eval()
    total_loss, total_correct_bits, exact_matches, total_samples = 0.0, 0, 0, 0

    with torch.no_grad():
        for batch in dataloader:
            inputs = batch["pixel_values"].to(device)
            labels = batch["labels"].to(device)

            with torch.cuda.amp.autocast(enabled=FP16):
                outputs = model(inputs)
                logits = outputs.logits
                loss = criterion(logits, labels)

            total_loss += loss.item()

            # è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡
            preds = (torch.sigmoid(logits) > 0.5).float()
            total_correct_bits += (preds==labels).sum().item()
            exact_matches += torch.all(preds==labels, dim=1).sum().item()
            total_samples += labels.size(0)

    avg_loss = total_loss / len(dataloader)
    bit_accuracy = 100 * total_correct_bits / (total_samples * NUM_LABELS)
    exact_match_ratio = 100 * exact_matches / total_samples

    return avg_loss, bit_accuracy, exact_match_ratio


# ==============================================================================
# --- 4. ä¸»è®­ç»ƒæµç¨‹ (å…¨æ–°ï¼šå®Œå…¨æ‰‹åŠ¨çš„å…¨é‡å¾®è°ƒ) ---
# ==============================================================================

def main():
    # --- å‡†å¤‡ç¯å¢ƒ ---
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # --- åŠ è½½ Image Processor å’Œ æ¨¡å‹ (ä¸å†ä½¿ç”¨LoRA) ---
    print(f"åŠ è½½ Image Processor å’Œ Swin Transformer æ¨¡å‹: {MODEL_NAME}...")
    image_processor = AutoImageProcessor.from_pretrained(MODEL_NAME)

    model = AutoModelForImageClassification.from_pretrained(
        MODEL_NAME,
        num_labels=NUM_LABELS,
        problem_type="multi_label_classification",
        ignore_mismatched_sizes=True
    ).to(device)

    print("æ¨¡å‹å·²åˆ‡æ¢ä¸ºå…¨é‡å¾®è°ƒæ¨¡å¼ã€‚")

    # --- å‡†å¤‡æ•°æ®é›†å’ŒDataloaders ---
    print("å‡†å¤‡æ•°æ®é›†...")
    full_dataset = CountingDataset(
        image_dir=IMAGE_DIR,
        label_dir=LABEL_DIR,
        image_processor=image_processor
    )
    # full_dataset = RainwaterImageDataset(
    #     metadata_path=METADATA_PATH,
    #     images_dir=IMAGE_DIR,
    #     image_processor=image_processor
    # )

    train_size = int(0.995 * len(full_dataset))
    eval_size = len(full_dataset) - train_size
    train_dataset, eval_dataset = random_split(full_dataset, [train_size, eval_size])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)

    print(f"æ•°æ®é›†åˆ’åˆ†: {len(train_dataset)} è®­ç»ƒæ ·æœ¬, {len(eval_dataset)} éªŒè¯æ ·æœ¬ã€‚")

    # --- åˆå§‹åŒ–è®­ç»ƒç»„ä»¶ ---
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)
    scaler = torch.cuda.amp.GradScaler(enabled=FP16)

    # --- å¼€å§‹è®­ç»ƒå¾ªç¯ ---
    print(f"ğŸš€ å¼€å§‹Swin Transformerçš„å…¨é‡å¾®è°ƒè®­ç»ƒ... æ¯ {EVAL_EVERY_N_STEPS} æ­¥è¯„ä¼°ä¸€æ¬¡ã€‚")
    log_file = open(LOG_FILE, "w")
    global_step = 0
    best_eval_loss = float('inf')

    for epoch in range(NUM_EPOCHS):
        model.train()
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS}")

        for batch in progress_bar:
            inputs = batch["pixel_values"].to(device)
            labels = batch["labels"].to(device)

            optimizer.zero_grad()

            with torch.cuda.amp.autocast(enabled=FP16):
                outputs = model(pixel_values=inputs)
                logits = outputs.logits
                loss = criterion(logits, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            global_step += 1
            progress_bar.set_postfix({"train_loss": f"{loss.item():.6f}", "step": global_step})

            # --- æŒ‰æ­¥æ•°è¿›è¡Œè¯„ä¼° ---
            if global_step % EVAL_EVERY_N_STEPS==0:
                val_loss, bit_acc, exact_match = evaluate(model, eval_loader, criterion, device)

                log_message = (f"Step: {global_step} | Val Loss: {val_loss:.6f} | "
                               f"Bit Acc: {bit_acc:.2f}% | Exact Match: {exact_match:.2f}%")
                print(log_message)
                log_file.write(log_message + "\n")
                log_file.flush()

                if val_loss < best_eval_loss:
                    best_eval_loss = val_loss
                    save_path = os.path.join(OUTPUT_DIR, "best_model.pth")
                    # torch.save(model.state_dict(), save_path)
                    print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³ {save_path}")

                model.train()  # è¯„ä¼°ååˆ‡å›è®­ç»ƒæ¨¡å¼

    # --- ä¿å­˜æœ€ç»ˆæ¨¡å‹ ---
    print("âœ… è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹...")
    final_save_path = os.path.join(OUTPUT_DIR, "final_model.pth")
    torch.save(model.state_dict(), final_save_path)
    log_file.close()
    print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {final_save_path}")


if __name__=="__main__":
    main()